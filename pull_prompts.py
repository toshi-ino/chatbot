from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langsmith import Client

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

# LangSmithã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–
client = Client()

def pull_rag_system_prompt():
    """RAGã‚·ã‚¹ãƒ†ãƒ ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’LangSmithã‹ã‚‰å–å¾—"""
    try:
        prompt = client.pull_prompt("rag-system-prompt")
        print("âœ… RAGã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—ã—ã¾ã—ãŸ")
        return prompt
    except Exception as e:
        print(f"âŒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None

def pull_rag_with_model():
    """RAGã‚·ã‚¹ãƒ†ãƒ ï¼ˆãƒ¢ãƒ‡ãƒ«ä»˜ãï¼‰ã‚’LangSmithã‹ã‚‰å–å¾—"""
    try:
        chain = client.pull_prompt("rag-system-with-model", include_model=True)
        print("âœ… RAGã‚·ã‚¹ãƒ†ãƒ ï¼ˆãƒ¢ãƒ‡ãƒ«ä»˜ãï¼‰ã‚’å–å¾—ã—ã¾ã—ãŸ")
        return chain
    except Exception as e:
        print(f"âŒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆãƒ¢ãƒ‡ãƒ«ä»˜ãï¼‰ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None

def pull_conversation_prompt():
    """ä¼šè©±ç¶™ç¶šç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’LangSmithã‹ã‚‰å–å¾—"""
    try:
        prompt = client.pull_prompt("rag-conversation-prompt")
        print("âœ… ä¼šè©±ç¶™ç¶šãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—ã—ã¾ã—ãŸ")
        return prompt
    except Exception as e:
        print(f"âŒ ä¼šè©±ç¶™ç¶šãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None

def test_rag_prompt():
    """RAGãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("\nğŸ§ª RAGãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ...")

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
    prompt = pull_rag_system_prompt()
    if not prompt:
        return

    # ãƒ†ã‚¹ãƒˆç”¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨è³ªå•
    test_context = """
    Python ã¯1991å¹´ã«Guido van Rossumã«ã‚ˆã£ã¦é–‹ç™ºã•ã‚ŒãŸãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã§ã™ã€‚
    ã‚·ãƒ³ãƒ—ãƒ«ã§èª­ã¿ã‚„ã™ã„æ§‹æ–‡ãŒç‰¹å¾´ã§ã€åˆå¿ƒè€…ã«ã‚‚å­¦ã³ã‚„ã™ã„è¨€èªã¨ã—ã¦äººæ°—ãŒã‚ã‚Šã¾ã™ã€‚
    ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã€ã‚¦ã‚§ãƒ–é–‹ç™ºã€è‡ªå‹•åŒ–ãªã©æ§˜ã€…ãªåˆ†é‡ã§ä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚
    """

    test_question = "Pythonã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„"

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å®Ÿè¡Œ
    try:
        formatted_prompt = prompt.invoke({
            "context": test_context,
            "question": test_question
        })

        print("ğŸ“ ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:")
        print(formatted_prompt.to_string())

        # OpenAIãƒ¢ãƒ‡ãƒ«ã§å®Ÿè¡Œ
        model = ChatOpenAI(model="gpt-4o", temperature=0.1)
        response = model.invoke(formatted_prompt)

        print("\nğŸ¤– AIå¿œç­”:")
        print(response.content)

    except Exception as e:
        print(f"âŒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

def test_conversation_prompt():
    """ä¼šè©±ç¶™ç¶šãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("\nğŸ§ª ä¼šè©±ç¶™ç¶šãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ...")

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
    prompt = pull_conversation_prompt()
    if not prompt:
        return

    # ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ‡ãƒ¼ã‚¿
    test_context = """
    æ©Ÿæ¢°å­¦ç¿’ã¯äººå·¥çŸ¥èƒ½ã®ä¸€åˆ†é‡ã§ã€ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãŒãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è‡ªå‹•çš„ã«å­¦ç¿’ã™ã‚‹æŠ€è¡“ã§ã™ã€‚
    æ•™å¸«ã‚ã‚Šå­¦ç¿’ã€æ•™å¸«ãªã—å­¦ç¿’ã€å¼·åŒ–å­¦ç¿’ã®3ã¤ã®ä¸»è¦ãªã‚¿ã‚¤ãƒ—ãŒã‚ã‚Šã¾ã™ã€‚
    """

    test_chat_history = """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼: AIã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„
    ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ: AIã¯äººå·¥çŸ¥èƒ½ã®ã“ã¨ã§ã€äººé–“ã®çŸ¥èƒ½ã‚’æ¨¡å€£ã™ã‚‹æŠ€è¡“ã§ã™ã€‚
    """

    test_question = "æ©Ÿæ¢°å­¦ç¿’ã¨AIã®é–¢ä¿‚ã«ã¤ã„ã¦è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„"

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å®Ÿè¡Œ
    try:
        formatted_prompt = prompt.invoke({
            "context": test_context,
            "chat_history": test_chat_history,
            "question": test_question
        })

        print("ğŸ“ ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:")
        print(formatted_prompt.to_string())

        # OpenAIãƒ¢ãƒ‡ãƒ«ã§å®Ÿè¡Œ
        model = ChatOpenAI(model="gpt-4o", temperature=0.1)
        response = model.invoke(formatted_prompt)

        print("\nğŸ¤– AIå¿œç­”:")
        print(response.content)

    except Exception as e:
        print(f"âŒ ä¼šè©±ç¶™ç¶šãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

def test_model_chain():
    """ãƒ¢ãƒ‡ãƒ«ä»˜ããƒã‚§ãƒ¼ãƒ³ã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("\nğŸ§ª ãƒ¢ãƒ‡ãƒ«ä»˜ããƒã‚§ãƒ¼ãƒ³ã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ...")

    # ãƒã‚§ãƒ¼ãƒ³ã‚’å–å¾—
    chain = pull_rag_with_model()
    if not chain:
        return

    # ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ‡ãƒ¼ã‚¿
    test_data = {
        "context": """
        LangSmithã¯LangChainãŒé–‹ç™ºã—ãŸLLMã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®é–‹ç™ºãƒ»ç›£è¦–ãƒ»è©•ä¾¡ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§ã™ã€‚
        ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ç®¡ç†ã€ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ã€è©•ä¾¡æ©Ÿèƒ½ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚
        """,
        "question": "LangSmithã®ä¸»ãªæ©Ÿèƒ½ã¯ä½•ã§ã™ã‹ï¼Ÿ"
    }

    try:
        # ãƒã‚§ãƒ¼ãƒ³ã‚’ç›´æ¥å®Ÿè¡Œ
        response = chain.invoke(test_data)

        print("ğŸ¤– ãƒã‚§ãƒ¼ãƒ³å®Ÿè¡Œçµæœ:")
        print(response)

    except Exception as e:
        print(f"âŒ ãƒã‚§ãƒ¼ãƒ³ã®å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

def list_available_prompts():
    """åˆ©ç”¨å¯èƒ½ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¸€è¦§ã‚’è¡¨ç¤º"""
    print("\nğŸ“‹ åˆ©ç”¨å¯èƒ½ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¸€è¦§:")

    prompt_names = [
        "rag-system-prompt",
        "rag-system-with-model",
        "rag-conversation-prompt"
    ]

    for name in prompt_names:
        try:
            prompt = client.pull_prompt(name)
            print(f"  âœ… {name} - åˆ©ç”¨å¯èƒ½")
        except Exception as e:
            print(f"  âŒ {name} - å–å¾—å¤±æ•—: {e}")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ”„ LangSmithã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—ã—ã¦ãƒ†ã‚¹ãƒˆã—ã¾ã™...\n")

    # åˆ©ç”¨å¯èƒ½ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç¢ºèª
    list_available_prompts()

    # å„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ†ã‚¹ãƒˆ
    test_rag_prompt()
    test_conversation_prompt()
    test_model_chain()

    print("\nâœ¨ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒ†ã‚¹ãƒˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")

if __name__ == "__main__":
    main()
